# 绪论
当前大模型层出不穷，国内国外都涌现了一系列大模型，由于chatgpt使用起来不是那么自由，可能很多人就会想着自己做一个自己的大模型，满足以下几点要求：
* 能够方便好用，不需要科学上网
* 可以免费无限次调用，效果还和GPT一样

高阶需求：
1. 可以无限调用API
2. 推理速度快，可以用于开发赚钱
3. 可以微调训练自己的知识库

这篇文章是我从0在笔记本实现低阶需求的一个尝试与记录。**先说明体验结果：对于个人笔记本显卡限制，推理速度还是太慢,但是！！！能用已经是最大的收获了**。推理效果对比GPT和chatglm，对比如下图：
![](../assets/2023-08-20-08-49-58.png)
![](../assets/2023-08-20-09-03-00.png)

** 个人认为，这种差异来自于模型本身和一些参数的设置问题。**
# 注意事项
1. 建议在windows上用**git操作**，因为可以用linux命令行，体验感会更好
2. 在开始运行前可以先**按照教程**设置好下载模型的路径，不然windows会下载到C盘
3. 开始运行前建议先**按照教程**分配好内存和显存

# 执行记录

1. 本地体验
![](../assets/2023-08-20-09-03-53.png)

2. 网页体验
JittorLLM通过gradio库，允许用户在浏览器之中和大模型直接进行对话。
```sh
python web_demo.py chatglm
```
![](../assets/2023-08-20-08-42-58.png)
网页体验感觉一般？因为每次输入就会显示Error，

